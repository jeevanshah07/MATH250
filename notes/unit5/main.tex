\section{Unit 5}
\subsection{Lecture 19: Eigenvalues and Eigenvectors}
\begin{defbox}{}{}{}
    Let $A$ be any $n\times\,n$ matrix. A \underline{non-zero} vector $\vec{S}$ is called an \textbf{eigenvector} of $A$ is $A\vec{S} = \lambda\vec{S}$ for $\lambda \in \CC$. Such $\lambda$ is called the corresponding \textbf{eigenvalue} of $A$.
\end{defbox}

\begin{example}{}{}
    Given $A$ and $\vec{S}$ below, verify $\vec{S}$ is an eigenvector of $A$ and find the corresponding eigenvalue of $A$.  
    \[
        A = \begin{pmatrix}
            -5 & -4 \\ 8 & 7
        \end{pmatrix}
        \text{ and } 
        \vec{S} = \begin{pmatrix}
            1 \\ -2
        \end{pmatrix}
    \]
    \begin{solution}
        \begin{align*}
            AS &= \begin{pmatrix}
                -5 & -4 \\ 8 & 7
            \end{pmatrix}
            \begin{pmatrix}
                1 \\ -2
            \end{pmatrix} \\
            &= \begin{pmatrix}
                3 \\ -6
            \end{pmatrix} \\
            &= 3\vec{S} \\
            &\Rightarrow \boxed{\lambda = 3}
        \end{align*}
    \end{solution}
\end{example}

\begin{example}{}{}
    Given $A$ below and $\lambda=2$, find the eigenvector
    \[
        A = \begin{pmatrix}
            5 & -1 \\ 3 & 1
        \end{pmatrix} 
    \]
    \begin{solution}
        Since $\lambda$ is an eigenvalue it must satisfy the equation 
        \[
            A\vec{S} = 2\vec{S} \Rightarrow A\vec{S} - 2\vec{S} = 0
        \]
        However, since $2$ is a scalar we can't factor out $\vec{S}$. We can fix this by multiplying by the identity matrix $I$. This gives
        \[
            I\left(A\vec{S} - 2\vec{S}\right) = AI\vec{S} - 2I\vec{S} = \left(A - 2I\right)\vec{S} = 0.
        \]
        Since $\vec{S}$ is non-zero by definition, we know that $A-2I=0$. So, 
        \begin{align*}
            \begin{pmatrix}
                5 & -1 \\ 3 & 1
            \end{pmatrix} - 2\begin{pmatrix}
                1 & 0 \\ 0 & 1
            \end{pmatrix}
            &= \begin{pmatrix}
                3 & -1 \\ 3 & -1
            \end{pmatrix}
            \xrightarrow{R_2 \to R_2-R_1}
            \begin{pmatrix}
                3 & -1 \\ 0 & 0
            \end{pmatrix} \\
            &\Rightarrow X = t\begin{pmatrix}
                1 \\ 3
            \end{pmatrix}.
        \end{align*}
        Thus, our eigenvector is 
        \[
            \boxed{\begin{pmatrix}
                1 \\ 3
            \end{pmatrix}} 
        \]
    \end{solution}
\end{example}

You may notice that in the above example the solution to $A-2I$ was 
\[
    t\begin{pmatrix}
        1 \\ 3
    \end{pmatrix}.
\]
Since this generates vectors for all non-zero values of $t$ we call this the \textbf{eigenspace}.


Its important to realize that for any $n\times\,n$ matrix $A$, if $\det A=0$ then $\det A-\lambda\,I = 0$. If $\det A = 0$ then $\rank A < n$ implies that the equation $A\mathbf{x} = 0$ has \textit{non-trivial} solutions which is exactly what we are in search of. From this discussion we can now learn about the characteristic equation. 

\begin{defbox}{The Characteristic Equation}{}{}
    The \textbf{characteristic equation} of an $n\times\,n$ matrix $A$ is 
    \[
        \det A - \lambda\,I=0 
    \]
    and its solutions are the \underline{eigenvalues} of $A$.
\end{defbox}

It follows from the above definition that any characteristic equation will be a polynomial of degree $n$ and thus $A$ will have $n$ eigenvectors (including multiplicity). \\ To see this in example, lets determine the characteristic equation for any $2\times\,2$ matrix. Let $A$ be the $2\times\,2$ matrix below
\[
    A = \begin{pmatrix}
        a & b \\ c & d
    \end{pmatrix}.
\]
We can find the characteristic equation using the formula provided in the definition to give, 
\begin{equation}{\label{eq:5}}
    \det A - \lambda\,I_2 = \begin{vmatrix}
        a - \lambda & b \\
        c & d - \lambda
    \end{vmatrix} 
    = \left(a-\lambda\right)\left(d-\lambda\right) - bc = \lambda^2 - \lambda(a+d) + (ad - bc).
\end{equation}
This process can be repeated for any $n\times\,n$ matrix to find its general characteristic equation.

\begin{impbox}{How to find Eigenvectors and Eigenvalues}{\label{sec:1}}
    Let $A$ be an $n\times\,n$ matrix. To find the eigenvalues and eigenvectors of $A$: 
    \begin{enumerate}
        \item Find the eigenvalues by solving $\det\left(A-\lambda\,I\right)=0$ (the characteristic equation)
        \item For each eigenvalue, find the corresponding eigenvector(s) y solving $A - \lambda\,I = 0$.
    \end{enumerate}
\end{impbox}

Its also important to note that for a triangular matrix (upper or lower), its eigenvalues are simply the entires on the main diagonal. 

\begin{example}{}{}
    Find the eigenvalues and eigenvectors of $A$ below 
    \[
        A = \begin{pmatrix}
            5 & -1 \\ 3 & 1
        \end{pmatrix} 
    \]
    \begin{solution}
        We can find the characteristic equation by solving $\det A - \lambda\,I = 0$. This gives 
        \[
            \begin{vmatrix}
                5-\lambda & -1 \\ 3 & 1-\lambda
            \end{vmatrix} 
            = \lambda^2 - 6\lambda + 8 = 0 \Rightarrow (\lambda-4)(\lambda-2) = 0 \Rightarrow \lambda_1 = 4, \lambda_2 = 2.
        \]
        Thus we can find our eigenvectors:
        \begin{align*}
            &\Rightarrow A - 4I = \begin{pmatrix}
                1 & -1 \\ 3 & -3
            \end{pmatrix} \xrightarrow{R_2 \to R_2 - 3R_1} \begin{pmatrix}
                1 & -1 \\ 0 & 0
            \end{pmatrix}
            \Rightarrow X = t\begin{pmatrix}
                1 \\ 1
            \end{pmatrix} \\
            &\Rightarrow A - 2I = \begin{pmatrix}
                3 & -1 \\ 3 & -1 
            \end{pmatrix}
            \xrightarrow{R_2 \to R_2 - R_1} \begin{pmatrix}
                3 & -1 \\ 0 & 0
            \end{pmatrix}
            \Rightarrow X = t\begin{pmatrix}
                1 \\ 3
            \end{pmatrix}
        \end{align*}
        Therefore for all $t \neq 0$ our eigenvectors are 
        \[
            t\begin{pmatrix}
                1 \\ 1
            \end{pmatrix} \text{ and } t\begin{pmatrix}
                1 \\ 3
            \end{pmatrix}
        \]
    \end{solution}
\end{example}

\begin{defbox}{Eigenspace}{}
    The \textbf{eigenspace} is the null space of $A-\lambda\,I$ \underline{without} the zero vectors
\end{defbox}

\begin{example}{}{}
    If $S_1 = \left(\begin{smallmatrix}
        1 \\ 3
    \end{smallmatrix}\right)$ for $\lambda_1 = 2$ and $S_2 = \left(\begin{smallmatrix}
        1 \\ 1
    \end{smallmatrix}\right)$ for $\lambda_2 = 4$ what are the eigenspaces?
    \begin{solution}
        The eigenspace associated with $\lambda_1$ is 
        \[
            \Span{\begin{pmatrix}
                1 \\ 3
            \end{pmatrix}} \setminus \braces{\vec{0}}.
        \]
        The eigenspace associated with $\lambda_2$ is 
        \[
            \Span{\begin{pmatrix}
                1 \\ 1
            \end{pmatrix}} \setminus \braces{\vec{0}}.
        \]
    \end{solution}
\end{example}

Note that the symbol $\setminus$ is the set minus symbol and all it means is exclusion from the set. So $\Span{x} \setminus \braces{\vec{0}}$ would be read as `the span of the vector $\vec{x}$ without the zero vector'.

\begin{thm}{}{\label{thm:2}}
    If $\vec{v_1},\ldots,\vec{v_r}$ are the eigenvectors that correspond to the eigenvalues $\lambda_1,\ldots,\lambda_r$ for an $n\times\,n$ matrix then the set $\braces{\vec{v_1}, \ldots, \vec{v_r}}$ is linearly independent.  
\end{thm}

\subsection{Lecture 20: The Characteristic Equation and Complex Eigenvalues [5.2, 5.5]}
\begin{impbox}{}
    Let $A$ be an $n\times\,n$ matrix. Then $A$ is invertible if, and only if, $0$ is \textbf{not} an eigenvalue of $A$.
\end{impbox}

\begin{defbox}{The Characteristic Equation}{}
    The \textbf{characteristic equation} is $\det(A-\lambda\,I) = 0$.
\end{defbox}

With this definition, we can now think of an eigenvalue of $A$ as a number $\lambda\in\CC$ if, and only if, $\lambda$ satisfies the characteristic equation. If you recall how to find eigenvalues, from~(\ref{sec:1}), this should make logical sense.

If $A$ is $n\times\,n$ then $\det\left(A-\lambda\,I\right)$ will be a polynomial of degree $n$, called the \textbf{characteristic polynomial}.

\begin{defbox}{Similarity}{}
    If $A$ and $B$ are $n\times\,n$ matricies, then $A$ is \textbf{similar to} $B$ if there is an invertible matrix $P$ such that $P^{-1}AP=B$, or equivalently, $A=PBP^{-1}$. Changing $A$ into $P^{-1}AP$ is called a \textbf{similarity transform}. 
\end{defbox}
It's worth mentioning that $A$ being similar to $B$ implies that $B$ is similar to $A$, but we just say that $A$ is similar to $B$. 

\begin{thm}{}{}
    If $n\times\,n$ matricies $A$ and $B$ are similar, then they have the same characteristic polynomial and hence the same eigenvalues with the same multiplicity.
\end{thm}

\begin{example}{}{}
    Let $A$ be the matrix below. Find the eigenvalues of $A$, and find a basis for each eigenspace.
    \[
        A = \begin{pmatrix}
            0.5 & -0.6 \\
            0.75 & 1.1
        \end{pmatrix} 
    \]
    \begin{solution}
        Using the formula from equation~(\ref{eq:5}) we can find the characteristic polynomial to be $\lambda^2-1.6\lambda+1=$. A quick glance should tell us that this is not factorable so using the quadractic equation we have
        \[
            \lambda = \frac{1.6\pm\sqrt{(-1.6)^{2} - 4}}{2} = .8 \pm .6i.
        \]
        Now, we follow the steps to find eigenvectors as normal
        \[
            A - (.8-.6i)I = \begin{pmatrix}
                -.3+.6i & -.6 \\
                .75 & .3+.6i
            \end{pmatrix} 
            \Rightarrow
            \begin{cases}
                \left(-.3+.6i\right)x_1 - .6x_2 &= 0 \\
                .75x_1 + \left(.3 + .6i\right)x_2 &= 0
            \end{cases}
        \]
        Since $\lambda = .8-.6i$ is an eigenvalue we know that the solutions to the homogenous system are non-trivial (i.e. $X\neq\,0$). This allows us to write $x_1$ and $x_2$ in terms of each other. We can use this to write 
        \[
            x_1 = (-.4-.8i)x_2
        \]
        from the second equation in the system. Thus our eigenvector (and basis) will be 
        \[
            \boxed{S_1 = \begin{pmatrix}
                -2 - 4i \\ 5
            \end{pmatrix}}
        \]
        Because complex numbers always come in conjugate pairs we can easily see that 
        \[
            \boxed{S_2 = \begin{pmatrix}
                -2 + 4i \\ 5
            \end{pmatrix}}
        \]
        If you aren't convinced, you can apply the same process as above using $\lambda = .8 + .6i$.
    \end{solution}
\end{example}

\subsection{Lecture 22: Diagonalization [5.3]}
Recall that a diagonal matrix is any matrix in the form 
\[
    \begin{pmatrix}
        a_{11} & 0 & \cdots & 0 \\
        0 & a_{22} & \cdots & 0 \\
        \vdots &  & \ddots &  \\
        0 & \cdots & 0 & a_{nn}
    \end{pmatrix}.
\]
In other words, a diagonal matrix is a matrix whos only non-zero entries lie on the main diagonal. For any diagonal matrix, $D$, we have the following fact:
\begin{equation}{\label{eq:1}}
    D = \begin{pmatrix}
        a_{11} & \cdots & 0 \\
        0 & \ddots & \vdots \\
        0 & \cdots & a_{nn}
    \end{pmatrix}
    \Rightarrow 
    D^{k} = \begin{pmatrix}
        (a_{11})^{k} & \cdots & 0 \\
        0 & \ddots & \vdots \\
        0 & \cdots & (a_{nn})^{k}
    \end{pmatrix}.
\end{equation}

With this in mind, consider the following example:
\begin{example}{}{}
    Let $A, P,$ and $D$ be given below. Find a formaul for $A^{k}$ if $A=PDP^{-1}$.
    \[
        A = \begin{pmatrix}
            7 & 2 \\ -4 & 1
        \end{pmatrix}, 
        \quad D = \begin{pmatrix}
            5 & 0 \\ 0 & 3 
        \end{pmatrix}, 
        \text{ and }
        P = \begin{pmatrix}
            1 & 1 \\ -1 & -2    
        \end{pmatrix}
    \]
    \begin{solution}
        Since $A=PDP^{-1}$ it would be a good first step to find $P^{-1}$. We can do this quickly using the formula for the inverse of a $2\times\,2$ matrix:
        \[
            P^{-1} = \frac{1}{-1}\begin{pmatrix}
                -2 & -1 \\ 1 & 1
            \end{pmatrix} = \begin{pmatrix}
                2 & 1 \\ -1 & -1
            \end{pmatrix}.
        \]
        Now before we jump straight to the formula for $A^{k}$ lets consider a few concrete examples. 
        \begin{align*}
            A^2 &= \left(PDP^{-1}\right)\left(PDP^{-1}\right) = PDP^{-1}PDP^{-1} = PDDP^{-1} = PD^{2}P^{-1} \\
            A^3 &= (PDP^{-1})(PD^{2}P^{-1}) = PDP^{-1}PD^{2}P^{-1} = PDD^{2}P^{-1} = PD^{3}P^{-1}
        \end{align*}
        Using these two examples, we can pretty clearly generalize for the pattern 
        \begin{equation}{\label{eq:2}}
            A^{k} = PD^{k}P.
        \end{equation}
        Now we can apply equation~(\ref{eq:1}) to equation~(\ref{eq:2}) in matrix form to see that we have 
        \[
            A^{k} = \begin{pmatrix}
                1 & 1 \\ -1 & -2    
            \end{pmatrix}
            \begin{pmatrix}
                5^k & 0 \\
                0 & 3^k
            \end{pmatrix}
            \begin{pmatrix}
                1 & 1 \\ -1 & -2
            \end{pmatrix}.
        \]
        Working our way from left to right multiplying the matricies will give us that 
        \[
            \boxed{A^{k} = \begin{pmatrix}
                2\cdot\,5^{k}-3^{k} & 5^{k}-3^{k} \\
                2\cdot\,3^{k}-2\cdot\,5^{k} & 2\cdot\,3^{k}-5^{k}
            \end{pmatrix}}
        \]
    \end{solution}
\end{example}

\begin{defbox}{Diagonalizable Matricies}{}
    A \underline{square} matrix $A$ is said to be \textbf{diagonalizable} if, and only if, $A$ is similar to some diagonal matrix, that is $A=PDP^{-1}$ for some invertible matrix $P$ and some diagonal matrix $D$.
\end{defbox}

\begin{thm}{}{\label{thm:1}}
    An $n\times\,n$ matrix $A$ is diagonalizable if, and only if, $A$ has $n$ linearly independent eigenvectors. In fact $A=PDP^{-1}$ with $D$ a diagonal matrix, if and only if, the columns of $P$ are $n$ linearly independent eigenvectors of $A$. In this case the diagonal entries of $D$ are eigenvalues of $A$ that correspond, respectively, to the eigenvectors in $P$. 
\end{thm}

\begin{example}{}{}
    Diagonalize the matrix below with characteristic equation $-\lambda^{3}-3\lambda^{2}+4$
    \[
        A = \begin{pmatrix}
            1 & 3 & 3 \\
            -3 & -5 & -3 \\
            3 & 3 & 1
        \end{pmatrix} 
    \]
    \begin{solution}
        We can start by finding the eigenvalues. Notice that $-\lambda^{3}-3\lambda^{2}+4 = -\left(\lambda-1\right)\left(\lambda+2\right)^{2}$ so the eigenvalues are $\lambda=1$ and $\lambda=-2$ (multiplicity 2). Next we can find our eigenvectors by solving $A-\lambda\,I$ for each value of $\lambda$.
        \begin{align*}
            \lambda = 1&: \vec{v_1} = \begin{pmatrix}
                1 \\ -1 \\ 1
            \end{pmatrix} \\
            \lambda = -2&: \vec{v_2} = \begin{pmatrix}
                -1 \\ 1 \\ 0
            \end{pmatrix}
            \text{ and }
            \vec{v_3} = \begin{pmatrix}
                -1 \\ 0 \\ 1
            \end{pmatrix}
        \end{align*}
        We can now apply Theorem~(\ref{thm:1}) to find $P$: 
        \[
            P = \begin{pmatrix}
                \left(\vec{v_1}\right) & \left(\vec{v_2}\right) & \left(\vec{v_3}\right)
            \end{pmatrix} 
            = \begin{pmatrix}
                1 & -1 & -1 \\
                -1 & 1 & 0 \\
                1 & 0 & 1
            \end{pmatrix}
        \]
        Once again, following Theorem~(\ref{thm:1}) we can find $D$ according to the order of eigenvectors used to contstruct $P$:
        \[
            D = \begin{pmatrix}
                1 & 0 & 0 \\
                0 & -2 & 0 \\
                0 & 0 & -2
            \end{pmatrix}
        \]
        You'll notice that we repeated $\lambda=-2$ twice because of its multiplicity. And thus, $D$ is our diagonalized matrix!
    \end{solution}
\end{example}

\begin{thm}{}{}
    An $n\times\,n$ matrix with $n$ distinct eigenvalues is diagonalizable.
\end{thm}

\begin{example}{}{}
    Determine if $A$ below is diagonalizable. 
    \[
        A = \begin{pmatrix}
            5 & -8 & 1 \\
            0 & 0 & 7 \\
            0 & 0 & 2
        \end{pmatrix} 
    \]
    \begin{solution}
        Since $A$ is an (upper) triangular matrix and square, we know that its eigenvalues are the diagonal entries with $\lambda_1 = 5, \lambda_2 = 0$ and $\lambda_3 = 2$. Since $A$ is a $3\times\,3$ matrix with $3$ distinct eigenvalues ($\lambda_1 \neq \lambda_2 \neq \lambda_3$), $A$ is diagonalizable.
    \end{solution}
\end{example}

So far we've been working with $n\times\,n$ matricies that have $n$ distinct eigenvalues and eigenvectors $\vec{v_1}$ through $\vec{v_n}$. This makes $P$ automatically invertible since its columns are linearly independent (by Theorem~(\ref{thm:2})). However, if a matrix has less than $n$ distinct eigenvalues, we can still contstruct $P$ in such a way to make it diagonalizable.

\begin{thm}{}{}
    Let $A$ be an $n\times\,n$ matrix whose distinct eigenvalues are $\lambda_1,\ldots,\lambda_p$. 
    \begin{enumerate}
        \item For $1 \leq k \leq p$, the dimension of the eigenspace for $\lambda_k$ is less than or equal to the multiplicity of the eigenvalue $\lambda_k$
        \item The matrix $A$ is diagonalizable if, and only if, the sum of the dimensions of the eigenspaces equals $n$, and this happens if, and only if, 
        \begin{enumerate}
            \item the characteristic polynomial factors completely into linear factors and 
            \item the dimension of the eigenspace for $\lambda_k$ equal the multiplicity of $\lambda_k$ 
        \end{enumerate}
        \item If $A$ is diagonalizable and $\mathcal{B}_k$ is a basis for the eigenspace corresponding to $\lambda_k$ for each $k$, then the total collection of vectors in the sets $\mathcal{B}_1, \ldots, \mathcal{B}_p$ forms an eigenvector basis for $\RR^{n}$.
    \end{enumerate}
\end{thm}